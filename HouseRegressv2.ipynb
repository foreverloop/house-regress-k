{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "#graphs and utilities\n",
    "import os\n",
    "import pandas as pd #pandas stands for panel data\n",
    "import numpy as np\n",
    "import math as ma\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Analysis\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "\n",
    "#regression models\n",
    "from scipy.stats import linregress as linRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "#model metrics, deciding which models perform best\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "df_train = pd.read_csv(\"../input/train.csv\")\n",
    "df_test = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "all_dfs = [df_train,df_test]\n",
    "\n",
    "def makeDict(df,label):\n",
    "    strcat_dict = {}\n",
    "    for i,row in df.iterrows():\n",
    "        strcat_dict[row[label]] = i \n",
    "    return strcat_dict\n",
    "\n",
    "def makeOrdinal(df,label,showDict):\n",
    "    filtered = df.sort_values([label], ascending = [True])\n",
    "    df_filtered = filtered.groupby(label).first().reset_index()\n",
    "    strcat_dict = {}\n",
    "    \n",
    "    for i,row in df_filtered.iterrows():\n",
    "        strcat_dict[row[label]] = i \n",
    "    \n",
    "    if showDict:\n",
    "        print(strcat_dict)\n",
    "    \n",
    "    for j,row in df.iterrows():\n",
    "        df.at[j,label] = strcat_dict.get(row[label])\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#quick way to see what data is missing \n",
    "sns.set_style(\"whitegrid\")\n",
    "missing = df_train.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "missing.sort_values(inplace=True)\n",
    "missing.plot.bar()\n",
    "\n",
    "#90% threshold makes it ok to drop these columns, too much data missing to make these useful\n",
    "drop_cols = []\n",
    "for val,column in missing.iteritems():\n",
    "    if column > (len(df_train)*.90):\n",
    "        drop_cols.append(val)\n",
    "\n",
    "for df in all_dfs:\n",
    "    df.drop(drop_cols,inplace=True, axis=1)\n",
    "\n",
    "all_dfs = [df_train,df_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantitative = [f for f in df_train.columns if df_train.dtypes[f] != 'object']\n",
    "quantitative.remove('SalePrice')\n",
    "quantitative.remove('Id')\n",
    "qualitative = [f for f in df_train.columns if df_train.dtypes[f] == 'object']\n",
    "\n",
    "for column in qualitative:\n",
    "    for df_single in all_dfs:\n",
    "        makeOrdinal(df_single,column,False)\n",
    "        \n",
    "all_dfs = [df_train,df_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distplot stands for distribution plot (so we can see how the data for SalePrice is distributed)\n",
    "y = df_train['SalePrice']\n",
    "plt.figure(1); plt.title('Johnson SU')\n",
    "sns.distplot(y, kde=False, fit=stats.johnsonsu)\n",
    "plt.figure(2); plt.title('Normal')\n",
    "sns.distplot(y, kde=False, fit=stats.norm)\n",
    "plt.figure(3); plt.title('Log Normal')\n",
    "sns.distplot(y, kde=False, fit=stats.lognorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normality = lambda x: stats.shapiro(x.fillna(0))[1] < 0.05\n",
    "normal = pd.DataFrame(df_train[quantitative])\n",
    "normal = normal.apply(test_normality)\n",
    "print(not normal.any())\n",
    "#so none of the quantitiative variables are normally distrubted at a 1% significance level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman(frame, features):\n",
    "    spr = pd.DataFrame()\n",
    "    spr['feature'] = features\n",
    "    spr['spearman'] = [frame[f].corr(frame['SalePrice'], 'spearman') for f in features]\n",
    "    spr = spr.sort_values('spearman')\n",
    "    print(spr['feature'])\n",
    "    plt.figure(figsize=(6, 0.25*len(features)))\n",
    "    sns.barplot(data=spr, y='feature', x='spearman', orient='h')\n",
    "    \n",
    "spearman(df_train,quantitative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman(df_train,qualitative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketData(df,column_to_bucket):\n",
    "    number_of_buckets = 5\n",
    "    df['tempBand'] = pd.qcut(df[column_to_bucket],number_of_buckets)\n",
    "    intervals = df['tempBand'].unique().sort_values().tolist()\n",
    "    intervals = [x for x in intervals if str(x) != 'nan']\n",
    "    \n",
    "    interval_dict = {}\n",
    "    for idx,interval in enumerate(intervals):\n",
    "        interval_dict['low'+str(idx)] = interval.left\n",
    "        interval_dict['high'+str(idx)] = interval.right\n",
    "    \n",
    "    df.loc[ df[column_to_bucket] <= interval_dict['high0'], column_to_bucket] = 0\n",
    "    df.loc[(df[column_to_bucket] > interval_dict['low1']) & \\\n",
    "           (df[column_to_bucket] <= interval_dict['high1']), column_to_bucket] = 1\n",
    "    df.loc[(df[column_to_bucket] > interval_dict['low2']) & \\\n",
    "           (df[column_to_bucket] <= interval_dict['high2']), column_to_bucket] = 2\n",
    "    df.loc[(df[column_to_bucket] > interval_dict['low3']) & \\\n",
    "           (df[column_to_bucket] <= interval_dict['high3']), column_to_bucket] = 3\n",
    "    df.loc[ df[column_to_bucket] > interval_dict['low4'], column_to_bucket] = 4\n",
    "    \n",
    "    df = df.drop(['tempBand'], axis=1)\n",
    "\n",
    "for df in all_dfs:\n",
    "    bucketData(df,'YearBuilt')\n",
    "for df in all_dfs:\n",
    "    bucketData(df,'LotFrontage')\n",
    "for df in all_dfs:\n",
    "    bucketData(df,'LotArea')\n",
    "\n",
    "all_dfs = [df_train,df_test]\n",
    "plt.hist(df_train['YearBuilt'])\n",
    "plt.hist(df_train['LotFrontage'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "float_cols = [cname for cname in df_train.columns if df_train[cname].dtype in ['float64']]\n",
    "float_cols.extend(['KitchenQual','GarageFinish','BsmtQual','ExterQual','Foundation'])\n",
    "\n",
    "for column in float_cols:\n",
    "    for df in all_dfs:\n",
    "        df[column] = df[column].fillna(int(df[column].mean()))\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "missing = df_train.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "missing.sort_values(inplace=True)\n",
    "missing.plot.bar()\n",
    "\n",
    "df_train[float_cols] = df_train[float_cols].astype(int)\n",
    "\n",
    "hold_columns = df_train[float_cols].columns\n",
    "df_train[float_cols] = pd.DataFrame(feature_imputer.fit_transform(df_train[float_cols].values))\n",
    "df_train[float_cols].columns = hold_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_choices = ['YearRemodAdd','1stFlrSF','GarageYrBlt','TotalBsmtSF','FullBath','GarageArea',\\\n",
    "                 'LotFrontage','LotArea','YearBuilt','GarageCars','GrLivArea','OverallQual','SalePrice',\\\n",
    "                 'KitchenQual','GarageFinish','BsmtQual','ExterQual','Foundation']\n",
    "\n",
    "best_features = df_train[final_choices]\n",
    "\n",
    "y = best_features['SalePrice']\n",
    "sale_predictors = best_features.drop(['SalePrice'], axis=1)\n",
    "\n",
    "X = sale_predictors\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,random_state=0)\n",
    "\n",
    "my_imputer = SimpleImputer(strategy='mean')\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns\n",
    "\n",
    "stdscale = StandardScaler()\n",
    "scaled_imputed_X_train = stdscale.fit_transform(imputed_X_train)\n",
    "scaled_imputed_X_valid = stdscale.fit_transform(imputed_X_valid)\n",
    "\n",
    "pca_fin = scaled_imputed_X_train\n",
    "pca_fin_val = scaled_imputed_X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit and predict with models and measure their accuracy\n",
    "#when r2 = 1, it's a perfect prediction\n",
    "reg_scores = pd.DataFrame(columns=['name','mean-sq-err','variance'])\n",
    "seed = 0\n",
    "\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(pca_fin,y_train)\n",
    "lin_reg_pred = linear_reg.predict(pca_fin_val)\n",
    "reg_scores.loc[0] = ['linear regression',\\\n",
    "                     int(mean_squared_error(y_valid, lin_reg_pred)),r2_score(y_valid, lin_reg_pred)]\n",
    "\n",
    "ada_reg = AdaBoostRegressor(DecisionTreeRegressor(max_depth=7),n_estimators=300, random_state=seed)\n",
    "ada_reg.fit(pca_fin,y_train)\n",
    "ada_reg_pred = ada_reg.predict(pca_fin_val)\n",
    "reg_scores.loc[1] = ['adaboost regression',\\\n",
    "                     int(mean_squared_error(y_valid, ada_reg_pred)),r2_score(y_valid, ada_reg_pred)]\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_estimators=350, random_state=seed)\n",
    "rf_reg.fit(pca_fin,y_train)\n",
    "rf_reg_pred = rf_reg.predict(pca_fin_val)\n",
    "reg_scores.loc[2] = ['random forest regression',\\\n",
    "                     int(mean_squared_error(y_valid, rf_reg_pred)),r2_score(y_valid, rf_reg_pred)]\n",
    "\n",
    "knn_reg = KNeighborsRegressor(weights='uniform')\n",
    "knn_reg.fit(pca_fin,y_train)\n",
    "knn_reg_pred = knn_reg.predict(pca_fin_val)\n",
    "reg_scores.loc[3] = ['nearest neighbours regression',\\\n",
    "                     int(mean_squared_error(y_valid, knn_reg_pred)),r2_score(y_valid, knn_reg_pred)]\n",
    "\n",
    "best_alpha = 0.0001\n",
    "regr = Lasso(alpha=best_alpha, max_iter=50000)\n",
    "regr.fit(pca_fin, y_train)\n",
    "\n",
    "# Run prediction on training set to get a rough idea of how well it does.\n",
    "lasso_reg_pred = regr.predict(pca_fin_val)\n",
    "\n",
    "reg_scores.loc[4] = ['lasso',\\\n",
    "                    int(mean_squared_error(y_valid, lasso_reg_pred)),r2_score(y_valid, lasso_reg_pred)]\n",
    "\n",
    "#only works on kaggle for now, since there's too many hoops to jump through to local install xgb\n",
    "xgb_reg = XGBRegressor()\n",
    "xgb_reg.fit(pca_fin, y_train)\n",
    "xgb_reg_pred = xgb_reg.predict(pca_fin_val)\n",
    "reg_scores.loc[5] = ['gradient boost regression',\\\n",
    "                     int(mean_squared_error(y_valid, xgb_reg_pred)),r2_score(y_valid, xgb_reg_pred)]\n",
    "\n",
    "reg_scores.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_choices = ['YearRemodAdd','1stFlrSF','GarageYrBlt','TotalBsmtSF','FullBath','GarageArea',\\\n",
    "                 'LotFrontage','LotArea','YearBuilt','GarageCars','GrLivArea','OverallQual','SalePrice',\\\n",
    "                 'KitchenQual','GarageFinish','BsmtQual','ExterQual','Foundation']\n",
    "\n",
    "final_choices_test = ['YearRemodAdd','1stFlrSF','GarageYrBlt','TotalBsmtSF','FullBath','GarageArea',\\\n",
    "                 'LotFrontage','LotArea','YearBuilt','GarageCars','GrLivArea','OverallQual',\\\n",
    "                 'KitchenQual','GarageFinish','BsmtQual','ExterQual','Foundation']\n",
    "\n",
    "X_test = df_test[final_choices_test]\n",
    "best_features = df_train[final_choices]\n",
    "y_train = best_features['SalePrice']\n",
    "sale_predictors = best_features.drop(['SalePrice'], axis=1)\n",
    "X_train = sale_predictors\n",
    "\n",
    "my_imputer = SimpleImputer(strategy='mean')\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train.values))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_test.values))\n",
    "\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_test.columns\n",
    "\n",
    "stdscale = StandardScaler()\n",
    "scaled_imputed_X_train = stdscale.fit_transform(imputed_X_train)\n",
    "scaled_imputed_X_valid = stdscale.fit_transform(imputed_X_valid)\n",
    "\n",
    "xgb_reg = XGBRegressor()\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "xgb_reg_pred = xgb_reg.predict(X_test)\n",
    "\n",
    "final_predictions = xgb_reg_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission = pd.DataFrame({ 'Id': df_test['Id'],\n",
    "                            'SalePrice': final_predictions })\n",
    "\n",
    "Submission.to_csv(\"Submission3.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
